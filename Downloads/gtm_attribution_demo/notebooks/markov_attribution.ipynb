{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Markov-Chains Multi-Touch Attribution (Portfolio Demo)\n", "\n", "This notebook builds a **first-order Markov chain** over GTM **channels** to estimate each channel's contribution via the **removal effect** method.\n", "\n", "**Pipeline:**\n", "1. Load closed-won opportunities and their pre-conversion touch sequences (within lookback window).\n", "2. Build transitions including `START` and absorbing states `CONVERT`, `NULL`.\n", "3. Estimate transition probabilities `P(channel_j | channel_i)`.\n", "4. Compute baseline conversion probability, then **remove** each channel and recompute; the delta is the channel's **Markov attribution**.\n", "\n", "> Dataset comes from `warehouse/gtm.db` built by `python -m etl.run_pipeline`.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pathlib import Path\n", "import sqlite3\n", "import pandas as pd\n", "import numpy as np\n", "\n", "ROOT = Path(__file__).resolve().parents[1]\n", "DB = ROOT/'warehouse'/'gtm.db'\n", "assert DB.exists(), 'Run: python -m etl.run_pipeline'\n", "con = sqlite3.connect(DB.as_posix())\n", "\n", "# Load touches and won opps\n", "touches = pd.read_sql_query('SELECT lead_id, channel, campaign, ts FROM touches ORDER BY ts', con, parse_dates=['ts'])\n", "opps = pd.read_sql_query('SELECT opp_id, lead_id, amount, created_at, closed_at FROM opportunities WHERE is_closed_won=1', con, parse_dates=['created_at','closed_at'])\n", "con.close()\n", "len(touches), len(opps)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Build channel sequences per won opportunity within a 60-day lookback before close\n", "LOOKBACK_DAYS = 60\n", "seqs = []\n", "for _, o in opps.iterrows():\n", "    lb = o['closed_at'] - pd.Timedelta(days=LOOKBACK_DAYS)\n", "    t = touches[(touches.lead_id==o.lead_id) & (touches.ts>=lb) & (touches.ts<=o.closed_at)].sort_values('ts')\n", "    if t.empty: continue\n", "    seqs.append(['START'] + t['channel'].tolist() + ['CONVERT'])\n", "len(seqs), seqs[0][:6] if seqs else []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Count transitions\n", "from collections import defaultdict\n", "edges = defaultdict(int)\n", "nodes = set()\n", "for s in seqs:\n", "    for a,b in zip(s[:-1], s[1:]):\n", "        edges[(a,b)] += 1\n", "        nodes.add(a); nodes.add(b)\n", "nodes = sorted(nodes)\n", "len(edges), list(edges.items())[:5]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Transition matrix P(b|a)\n", "import pandas as pd\n", "out_edges = {}\n", "for (a,b), c in edges.items():\n", "    out_edges.setdefault(a, 0)\n", "    out_edges[a] += c\n", "P = {}\n", "for (a,b), c in edges.items():\n", "    P[(a,b)] = c / out_edges[a]\n", "P_df = pd.DataFrame([{'from':a, 'to':b, 'p':p} for (a,b), p in P.items()])\n", "P_df.sort_values(['from','to']).head(10)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Compute baseline conversion probability from START via simulation (or absorbing Markov chain math)\n", "rng = np.random.default_rng(7)\n", "def step(state):\n", "    # sample next state from P\n", "    cand = [(b, p) for (a,b), p in P.items() if a==state]\n", "    if not cand:\n", "        return 'NULL'\n", "    to, probs = zip(*cand)\n", "    return rng.choice(to, p=probs)\n", "\n", "def simulate(n=20000, max_steps=50):\n", "    conv = 0\n", "    for _ in range(n):\n", "        s = 'START'\n", "        for _ in range(max_steps):\n", "            s = step(s)\n", "            if s in ('CONVERT','NULL'):\n", "                conv += int(s=='CONVERT')\n", "                break\n", "    return conv / n\n", "\n", "baseline = simulate(10000)\n", "baseline"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Removal effect: for each channel, remove its outgoing transitions and re-normalize, then recompute conversion rate\n", "channels = [n for n in nodes if n not in ('START','CONVERT','NULL')]\n", "def removal_effect(channel):\n", "    # build modified P without the channel\n", "    out = {}\n", "    totals = {}\n", "    for (a,b), p in P.items():\n", "        if a==channel or b==channel:\n", "            continue\n", "        out[(a,b)] = p\n", "        totals.setdefault(a, 0)\n", "        totals[a] += p\n", "    # renormalize\n", "    P2 = {}\n", "    for (a,b), p in out.items():\n", "        P2[(a,b)] = p / totals[a] if totals.get(a,0)>0 else 0\n", "    # simulate\n", "    rng2 = np.random.default_rng(9)\n", "    def step2(state):\n", "        cand = [(b, pr) for (x,b), pr in P2.items() if x==state]\n", "        if not cand:\n", "            return 'NULL'\n", "        to, probs = zip(*cand)\n", "        return rng2.choice(to, p=probs)\n", "    conv = 0\n", "    for _ in range(8000):\n", "        s='START'\n", "        for _ in range(50):\n", "            cand = [(b, pr) for (x,b), pr in P2.items() if x==s]\n", "            if not cand:\n", "                s='NULL'; break\n", "            s = step2(s)\n", "            if s in ('CONVERT','NULL'):\n", "                conv += int(s=='CONVERT'); break\n", "    return conv/8000\n", "\n", "rows=[]\n", "for ch in channels:\n", "    conv_rate = removal_effect(ch)\n", "    rows.append({'channel': ch, 'baseline_conv': baseline, 'conv_without': conv_rate, 'delta': baseline - conv_rate})\n", "markov_attr = pd.DataFrame(rows).sort_values('delta', ascending=False)\n", "markov_attr.head(10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Compare with heuristic models (optional)\n", "You can compare `markov_attr` with the heuristic attributions in the warehouse (`touch_attribution` table) to see alignment.\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11"}}, "nbformat": 4, "nbformat_minor": 5}